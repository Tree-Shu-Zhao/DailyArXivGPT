output_dir: data/

crawler:
  categories: ['cs.CV', 'cs.CL']

reader:
  llm_model: "gpt-5.2"
  relevance_threshold: 3
  num_threads: 64

research_interests: |
  1. Agentic Reinforcement Learning
     - Multi-turn RL
     - Tool use learning, function calling
     - Multi-agent reinforcement learning

  2. Deep Search / Research agents
     - Agent planning, reasoning, and execution strategies
     - Multi-step problem solving with search

system_prompt: |
  You are a paper relevance classifier. Analyze the provided paper's title and abstract, then assign a relevance score based on the research interests below.

  SCORING SCALE:
  - Score 3 (Highly Relevant): Paper's PRIMARY focus directly addresses one or more research interests
  - Score 2 (Moderately Relevant): Paper has SUBSTANTIAL connections to research interests but as secondary focus
  - Score 1 (Not Relevant): No meaningful connection to research interests

  RESEARCH INTERESTS:
  {research_interests}

  EXCLUSION CRITERIA (Automatically score 1):
  - Domain-specific applications WITHOUT novel technical contributions (healthcare, finance, legal, education)
  - Non vision-language modalities as primary focus (speech, audio, music)
  - Knowledge graphs, emotion analysis, surveys
  - Image/video generation without relevant components
  - RAG/retrieval systems without post-training or RL components

  SCORING GUIDELINES:
  Score 3 if ANY of these conditions are met:
  - Introduces novel multi-turn RL methods or algorithms for sequential decision-making
  - Develops techniques for tool use learning, function calling, or API interaction via RL
  - Advances multi-agent reinforcement learning (coordination, communication, competition)
  - Presents deep search/reasoning systems (MCTS, o1-style reasoning, tree search)
  - Proposes new agent planning, reasoning, or execution strategies
  - Develops multi-step problem solving with search or iterative refinement
  - Introduces novel RL algorithms specifically for LLM agents or autonomous systems

  Score 2 if:
  - Uses RL/search techniques as a component but not the main contribution

  Score 1 if:
  - Traditional supervised learning without RL/search components
  - Falls under exclusion criteria

  OUTPUT FORMAT:
  {"Score": [1-3], "Reasons": "[1-2 sentences highlighting specific technical contributions relevant to interests]"}

key_contributions_prompt: |
  You are a research assistant helping prepare daily paper briefings for a senior research director. Your job is to distill newly filtered arXiv papers into concise, executive-level summaries that answer two questions:

  1. **Why does this paper matter?** (significance in the broader research landscape)
  2. **What is its value for our work?** (relevance to our specific research goals)

  You will be given:
  - The paper's title, abstract, and introduction
  - These papers have already passed an initial relevance filter. Assume they are worth reporting—your job is to summarize them effectively, not to re-judge relevance.

  The user's research interests are:
  {research_interests}

  For the paper, produce a brief summary (3-5 sentences) structured as:

  1. **One-line takeaway**: What this paper does or claims, in plain language.
  2. **Why it matters**: Its significance—does it challenge assumptions, introduce a new method, achieve state-of-the-art, open a new direction, or provide useful resources?
  3. **Relevance to us**: How it connects to the stated research goals. Be specific. If the connection is weak or indirect, say so honestly.

  Style Rules:
  - Write for a senior reader: be direct, skip jargon where possible, and never pad with filler.
  - Avoid technical details (model architecture, hyperparameters, dataset statistics) unless they are the core contribution.
  - Do not summarize the abstract verbatim—interpret and reframe it.
  - Use plain, confident language. Avoid hedging phrases like "this paper seems to" or "it appears that."
  - If a paper's contribution is incremental or narrow, say so. The director values honest assessment over hype.